{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab63cf45-7e40-4449-88c9-2ffc9027fe4a",
   "metadata": {},
   "source": [
    "# Load wrist watches dataset to Astra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5ef72a-09f1-4aa5-887f-a4e6e826311e",
   "metadata": {},
   "source": [
    "## Create description and embeddings from images, then upload to Astra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79cb9cf5-33b2-4018-9d14-7c7be36692d6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Get Claude Sonnet description method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "48e25ad7-7318-46c9-a88e-108c4bc130e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################\n",
    "# Method to Get Claude Sonnet description from an image #\n",
    "#########################################################\n",
    "\n",
    "def claude_description(image):\n",
    "    # Variables for Bedrock API\n",
    "    category = 'wrist watches'\n",
    "    modelId = 'anthropic.claude-3-sonnet-20240229-v1:0'\n",
    "    contentType = 'application/json'\n",
    "    accept = 'application/json'\n",
    "    \n",
    "    prompt = \"\"\"\n",
    "    Identify the following product in the image provided.\n",
    "    Product Category: {product_category}\n",
    "    \n",
    "    Return an enhanced description of the product based on the image for better search results.\n",
    "    Do not include any specific details that can not be confirmed from the image such as the quality of materials, other color options, or exact measurements.\n",
    "    \"\"\"\n",
    "\n",
    "    # Messages\n",
    "    messages = [\n",
    "      {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "          {\n",
    "            \"type\": \"image\",\n",
    "            \"source\": {\n",
    "              \"type\": \"base64\",\n",
    "              \"media_type\": \"image/jpeg\",\n",
    "              \"data\": image\n",
    "            }\n",
    "          },\n",
    "          {\n",
    "            \"type\": \"text\",\n",
    "            \"text\": prompt.format(product_category=category)\n",
    "          }\n",
    "        ]\n",
    "      }\n",
    "    ]\n",
    "\n",
    "    # Body\n",
    "    claude_body = json.dumps({\n",
    "        \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "        \"max_tokens\": 1000,\n",
    "        \"messages\": messages\n",
    "    })\n",
    "\n",
    "    # Run Bedrock API to invoke Claude 3 model\n",
    "    claude_response = bedrock_runtime.invoke_model(\n",
    "      modelId=modelId,\n",
    "      contentType=contentType,\n",
    "      accept=accept,\n",
    "      body=claude_body\n",
    "    )\n",
    "\n",
    "    claude_response_body = json.loads(claude_response.get('body').read())\n",
    "    return claude_response_body['content'][0]['text']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a33d3a6-4b97-4189-bd19-aba51d806231",
   "metadata": {},
   "source": [
    "#### Get embedding with AWS Titan method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "a420c104-9470-41ae-9c71-b324a1adec72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Embeddings using Amazon Titan\n",
    "\n",
    "def generate_titan_embedding(input_text, input_image):\n",
    "    # Variables for Bedrock API\n",
    "    embedding_output_length = 1024\n",
    "    embedding_model_id = \"amazon.titan-embed-image-v1\"\n",
    "    contentType = 'application/json'\n",
    "    accept = 'application/json'\n",
    "    \n",
    "    titan_body = json.dumps({\n",
    "        \"inputText\": input_text,\n",
    "        \"inputImage\": input_image,\n",
    "        \"embeddingConfig\": {\n",
    "            \"outputEmbeddingLength\": embedding_output_length\n",
    "        }\n",
    "    })\n",
    "\n",
    "    titan_response = bedrock_runtime.invoke_model(\n",
    "        modelId=embedding_model_id,\n",
    "        contentType=contentType,\n",
    "        accept=accept,\n",
    "        body=titan_body\n",
    "    )\n",
    "\n",
    "    final_response = json.loads(titan_response.get('body').read())\n",
    "    return final_response['embedding']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91402e9-726f-4c57-acb1-aebc80b9e9f4",
   "metadata": {},
   "source": [
    "#### Final program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439ec1e9-0735-48e0-ba0e-b770bf6bef19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import base64\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from io import BytesIO\n",
    "from tqdm.auto import tqdm\n",
    "from astrapy.db import AstraDB, AstraDBCollection\n",
    "    \n",
    "####################################\n",
    "# Create AstraDB vector collection #\n",
    "####################################\n",
    "ASTRA_DB_ENDPOINT = \"\"\n",
    "ASTRA_DB_REGION = \"\"\n",
    "ASTRA_DB_TOKEN = \"\"\n",
    "ASTRA_DB_KEYSPACE = \"\"\n",
    "\n",
    "# Creation of AstraDB collection\n",
    "#catalog_collection = astra_db.create_collection(collection_name = \"watches_catalog\", dimension=1024)\n",
    "#print(\"Collection creation ended.\")\n",
    "\n",
    "# If using an existing collection\n",
    "print(\"Getting AstraDB collection...\")\n",
    "catalog_collection = AstraDBCollection(\n",
    "    collection_name=\"watches_catalog\", \n",
    "    astra_db=astra_db\n",
    ")\n",
    "\n",
    "#######################\n",
    "# Set AWS credentials #\n",
    "#######################\n",
    "# establish Bedrock client\n",
    "bedrock_runtime = boto3.client(\n",
    "    service_name=\"bedrock-runtime\",\n",
    "    aws_access_key_id=\"your_accesskey\",\n",
    "    aws_secret_access_key=\"your_secret\",\n",
    "    aws_session_token=\"Get the temporal token and put it here\",\n",
    "    endpoint_url=\"your service endpoint\",\n",
    "    region_name=\"us-east-1\",\n",
    ")\n",
    "\n",
    "def insert_catalog(row, new_df, index, max_steps, errors, progress_bar):\n",
    "    progress_bar.value = 0\n",
    "    try:        \n",
    "### Get the image from s3\n",
    "        BUCKET_NAME = \"name_of_your_bucket\"\n",
    "        s3_path = \"catalog/\"\n",
    "        full_obj_path = \"{img_path}{filename}\".format(img_path = s3_path, filename = row['image_name'])\n",
    "        s3 = boto3.client('s3')\n",
    "    \n",
    "        img_data = s3.get_object(Bucket=BUCKET_NAME, Key=full_obj_path)['Body'].read()\n",
    "    \n",
    "        # Update the progress bar / Retrieve image\n",
    "        progress_bar.value += 1 # signal to increment the progress bar\n",
    "        progress_bar.description = str(progress_bar.value) + \"/\" + str(max_steps) + \" - s3\" \n",
    "    \n",
    "### Get description from Claude ###\n",
    "        # b64 representation of the image for Claude\n",
    "        b64_img_data = base64.b64encode(img_data).decode(\"utf-8\")\n",
    "    \n",
    "        img_description = claude_description(b64_img_data)\n",
    "\n",
    "        # Update the progress bar / Get description\n",
    "        progress_bar.value += 1 # signal to increment the progress bar\n",
    "        progress_bar.description = str(progress_bar.value) + \"/\" + str(max_steps) + \" - Claude\" \n",
    "    \n",
    "### Get Embedding with Titan ###\n",
    "        embedding = generate_titan_embedding(img_description, b64_img_data)\n",
    "\n",
    "        # Update the progress bar / Get embedding\n",
    "        progress_bar.value += 1 # signal to increment the progress bar\n",
    "        progress_bar.description = str(progress_bar.value) + \"/\" + str(max_steps) + \" - Titan\" \n",
    "    \n",
    "### Add row to dataframe ###\n",
    "        new_df_row = [row['brand'], row['name'], row['price'], full_obj_path, img_description, embedding]\n",
    "        #new_df._append(new_df_row)\n",
    "        new_df.loc[len(new_df.index)] = new_df_row\n",
    "        \n",
    "        # Update the progress bar / Add row to dataframe\n",
    "        progress_bar.value += 1 # signal to increment the progress bar\n",
    "        progress_bar.description = str(progress_bar.value) + \"/\" + str(max_steps) + \" - Dataframe\" \n",
    "        \n",
    "### Add new row to AstraDB ###\n",
    "        catalog_collection.insert_one({\n",
    "            \"df_index\": index,\n",
    "            \"brand\": row['brand'],\n",
    "            \"product_name\": row['name'],\n",
    "            \"price\": row['price'],\n",
    "            \"category\": category,\n",
    "            \"file_path\": full_obj_path,\n",
    "            \"description\": img_description,\n",
    "            \"$vector\": embedding,\n",
    "        })\n",
    "\n",
    "        # Update the progress bar / Add row to AstraDB\n",
    "        progress_bar.value += 1 # signal to increment the progress bar\n",
    "        progress_bar.description = str(progress_bar.value) + \"/\" + str(max_steps) + \" - Astra\" \n",
    "\n",
    "    except Exception as error:\n",
    "        errors.append(f\"Error at IX {index} {error}\")\n",
    "\n",
    "#######################\n",
    "# Let the magic begin #\n",
    "#######################\n",
    "\n",
    "# Load de dataset CSV \n",
    "df = pd.read_csv(\"dataset/metadata.csv\", header = 0)\n",
    "new_df = pd.DataFrame(columns=['brand','name', 'price', 'file_path', 'description', 'embedding'])\n",
    "\n",
    "##########################################################\n",
    "# Define limits and restrictions (to make partial loads) #\n",
    "##########################################################\n",
    "skip = 0\n",
    "load_to = len(df)-1\n",
    "max_steps = 5\n",
    "\n",
    "errors = []\n",
    "tqdm.pandas()\n",
    "ip = IntProgress(min=0, max=max_steps) # instantiate the bar for each row\n",
    "display(ip) # display the bar\n",
    "\n",
    "for index, row in tqdm(df[skip:load_to].iterrows(), total=df[skip:load_to].shape[0], desc=f'Loading with Astrapy'):\n",
    "    insert_catalog(row, new_df, index, max_steps, errors, ip)\n",
    "\n",
    "# Export the resulting dataframe to an CSV file\n",
    "new_df.to_csv(\"dataset/watches_dataset.csv\", sep=',')\n",
    "\n",
    "print(\"Finished\")\n",
    "print(f\"Errors: {len(errors)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce074fff-20bd-4d8a-bc81-40ebcb5fe109",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eced9d2d-c8ce-49ad-8588-54b294c41b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(new_df.head())\n",
    "print(len(new_df.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a56eca-d033-47d8-8843-a1058b32ca90",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Store everything in AstraDB (for later use in vector search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f51b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load to vector store\n",
    "def load_to_astra(df, collection):\n",
    "  len_df = len(df)\n",
    "  f = IntProgress(min=0, max=len_df) # instantiate the bar\n",
    "  display(f) # display the bar\n",
    "  for i in range(len_df):\n",
    "    f.value += 1 # signal to increment the progress bar\n",
    "    f.description = str(f.value) + \"/\" + str(len_df)\n",
    "\n",
    "    product_name = df.loc[i, \"product_name\"]\n",
    "    link = df.loc[i, \"link\"]\n",
    "    product_images = df.loc[i,\"product_images\"]\n",
    "    price = df.loc[i, \"price\"]\n",
    "    details = df.loc[i, \"details\"]\n",
    "    category = df.loc[i, \"category\"]\n",
    "    gender = df.loc[i, \"gender\"]\n",
    "    embeddings = df.loc[i, \"embeddings\"]\n",
    "\n",
    "    try:\n",
    "      # add to the Astra DB Vector Database\n",
    "      collection.insert_one({\n",
    "          \"_id\": i,\n",
    "          \"product_name\": product_name,\n",
    "          \"link\": link,\n",
    "          \"product_images\": product_images,\n",
    "          \"price\": price,\n",
    "          \"details\": details,\n",
    "          \"category\": category,\n",
    "          \"gender\": gender,\n",
    "          \"$vector\": embeddings,\n",
    "        })\n",
    "    except Exception as error:\n",
    "      # if you've already added this record, skip the error message\n",
    "      error_info = json.loads(str(error))\n",
    "      if error_info[0]['errorCode'] == \"DOCUMENT_ALREADY_EXISTS\":\n",
    "        print(\"Document already exists in the database. Skipping.\")\n",
    "\n",
    "load_to_astra(df, collection)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
